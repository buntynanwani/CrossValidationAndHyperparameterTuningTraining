{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab0b87d9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4fa735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X and y successfully defined. X shape: (51, 11)\n"
     ]
    }
   ],
   "source": [
    "## üìö 1. Setup and Data Loading (Re-defining X and y)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "# --- Data Loading (Using your correct relative path) ---\n",
    "file_path = '../../datasets/Supplement_Sales_Weekly_Expanded.csv'\n",
    "try:\n",
    "    data = pd.read_csv(file_path) \n",
    "except:\n",
    "    # Use the absolute path if relative path fails again\n",
    "    # data = pd.read_csv('c:/f5/CrossValidationAndHyperparameterTuningTraining/datasets/Supplement_Sales_Weekly_Expanded.csv') \n",
    "    raise FileNotFoundError(\"Please check the path or ensure the file is accessible.\")\n",
    "\n",
    "\n",
    "# --- Feature Engineering (Condensed from previous steps) ---\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data['Year'] = data['Date'].dt.year\n",
    "data['Month'] = data['Date'].dt.month\n",
    "data = data.drop(columns=['Category', 'Revenue', 'Location'], errors='ignore')\n",
    "\n",
    "product_data_grouped = data.groupby(['Product_Name', 'Year', 'Month']).agg(\n",
    "    Price_Avg=('Price', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "product_data_grouped = product_data_grouped.sort_values(by=['Product_Name', 'Year', 'Month']).reset_index(drop=True)\n",
    "\n",
    "PRODUCT_ID = product_data_grouped['Product_Name'].unique()[0]\n",
    "product_data = product_data_grouped[product_data_grouped['Product_Name'] == PRODUCT_ID].copy()\n",
    "\n",
    "product_data['Time_Index'] = np.arange(len(product_data)) + 1\n",
    "product_data['Time_Index_Squared'] = product_data['Time_Index'] ** 2\n",
    "product_data['Month_sin'] = np.sin(2 * np.pi * product_data['Month'] / 12)\n",
    "product_data['Month_cos'] = np.cos(2 * np.pi * product_data['Month'] / 12)\n",
    "product_data['Price_Lag_1'] = product_data['Price_Avg'].shift(1)\n",
    "product_data['Price_Lag_3'] = product_data['Price_Avg'].shift(3)\n",
    "product_data['Price_Lag_12'] = product_data['Price_Avg'].shift(12)\n",
    "product_data['Price_MA_6'] = product_data['Price_Avg'].rolling(window=6).mean().shift(1)\n",
    "product_data['Price_MA_12'] = product_data['Price_Avg'].rolling(window=12).mean().shift(1)\n",
    "product_data = product_data.dropna().reset_index(drop=True)\n",
    "\n",
    "FEATURES = ['Year', 'Month', 'Month_sin', 'Month_cos', 'Time_Index', 'Time_Index_Squared', \n",
    "            'Price_Lag_1', 'Price_Lag_3', 'Price_Lag_12', 'Price_MA_6', 'Price_MA_12']\n",
    "TARGET = 'Price_Avg'\n",
    "\n",
    "X = product_data[FEATURES]\n",
    "y = product_data[TARGET]\n",
    "print(\"X and y successfully defined. X shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52c0554",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è 2. Why Standard K-Fold Fails for Time Series\n",
    "\n",
    "In Notebook 01, we used basic K-Fold to introduce the concept of averaging scores. However, K-Fold works by **randomly or sequentially splitting** the data, which means it:\n",
    "\n",
    "1.  **Breaks Chronological Order:** It puts future data into the training set and tests on past data.\n",
    "2.  **Allows Data Leakage:** The model \"sees\" data from the future to predict the past, leading to artificially low (overly optimistic) error scores.\n",
    "\n",
    "### üìö Analogy: Looking into the Future\n",
    "\n",
    "Imagine you are studying for a stock price exam (training). If your practice test (validation) includes stock prices from *after* the period you are studying, you are essentially **cheating** by looking into the future!\n",
    "\n",
    "The true test of a forecasting model is always: **Train on the PAST, Predict the FUTURE.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64f661a",
   "metadata": {},
   "source": [
    "## ‚û°Ô∏è 3. TimeSeriesSplit: The Expanding Window\n",
    "\n",
    "The correct technique for time-series CV is the **Expanding Window**.\n",
    "\n",
    "* **The Rule:** The training data set must **always** be chronologically earlier than the testing data set.\n",
    "* **The Process:** In each fold, the training window grows (expands) to include more historical data, and the test window always moves forward.\n",
    "\n",
    "### 3.1. Visualizing the Splits\n",
    "\n",
    "We will use `TimeSeriesSplit` with `n_splits=5`.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "n_splits = 5\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "# Let's visualize the size of the splits (using the index)\n",
    "print(f\"Total samples available: {len(X)}\")\n",
    "print(\"\\n--- Split Visualization ---\")\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(tscv.split(X), 1):\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\"  Training Window Size: {len(train_index)} (Index {train_index[0]} to {train_index[-1]})\")\n",
    "    print(f\"  Testing Window Size:  {len(test_index)} (Index {test_index[0]} to {test_index[-1]})\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# Note how the training window gets progressively larger with each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e34ca803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples available: 51\n",
      "\n",
      "--- Split Visualization ---\n",
      "Fold 1:\n",
      "  Training Window Size: 11 (Index 0 to 10)\n",
      "  Testing Window Size:  8 (Index 11 to 18)\n",
      "------------------------------\n",
      "Fold 2:\n",
      "  Training Window Size: 19 (Index 0 to 18)\n",
      "  Testing Window Size:  8 (Index 19 to 26)\n",
      "------------------------------\n",
      "Fold 3:\n",
      "  Training Window Size: 27 (Index 0 to 26)\n",
      "  Testing Window Size:  8 (Index 27 to 34)\n",
      "------------------------------\n",
      "Fold 4:\n",
      "  Training Window Size: 35 (Index 0 to 34)\n",
      "  Testing Window Size:  8 (Index 35 to 42)\n",
      "------------------------------\n",
      "Fold 5:\n",
      "  Training Window Size: 43 (Index 0 to 42)\n",
      "  Testing Window Size:  8 (Index 43 to 50)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "## ‚û°Ô∏è 3. TimeSeriesSplit: The Expanding Window (Visualization)\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit # Already imported, but good practice\n",
    "\n",
    "n_splits = 5\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "# Let's visualize the size of the splits (using the index)\n",
    "print(f\"Total samples available: {len(X)}\") # X is now defined\n",
    "print(\"\\n--- Split Visualization ---\")\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(tscv.split(X), 1):\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\"  Training Window Size: {len(train_index)} (Index {train_index[0]} to {train_index[-1]})\")\n",
    "    print(f\"  Testing Window Size:  {len(test_index)} (Index {test_index[0]} to {test_index[-1]})\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11a370bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual MAE scores for each TimeSeries Fold:\n",
      "[4.04692687 6.60213875 4.53034812 5.62726125 4.61567625]\n",
      "\n",
      "Final TimeSeries CV Score (Average MAE): $5.084\n",
      "Standard Deviation of MAE: 0.917\n"
     ]
    }
   ],
   "source": [
    "## 3.3. Running the TimeSeries CV with the Random Forest Model\n",
    "\n",
    "# --- ADD THIS LINE ---\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# --------------------\n",
    "from sklearn.ensemble import RandomForestRegressor # Ensure this is also imported if not done earlier\n",
    "\n",
    "# Re-initialize the model\n",
    "model_ts = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Use cross_val_score with the TimeSeriesSplit object (tscv)\n",
    "# We use neg_mean_absolute_error (MAE) as before.\n",
    "cv_scores_ts = cross_val_score(\n",
    "    model_ts, \n",
    "    X, \n",
    "    y, \n",
    "    cv=tscv, \n",
    "    scoring='neg_mean_absolute_error'\n",
    ")\n",
    "\n",
    "# Convert negative scores back to positive MAE errors\n",
    "cv_maes_ts = -cv_scores_ts \n",
    "\n",
    "print(\"Individual MAE scores for each TimeSeries Fold:\")\n",
    "print(cv_maes_ts)\n",
    "\n",
    "print(f\"\\nFinal TimeSeries CV Score (Average MAE): ${cv_maes_ts.mean():.3f}\")\n",
    "print(f\"Standard Deviation of MAE: {cv_maes_ts.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f57c377",
   "metadata": {},
   "source": [
    "## üåü 4. Comparison and Conclusion\n",
    "\n",
    "Let's compare the results from the two CV methods on our time-series data:\n",
    "\n",
    "| CV Method | Average MAE (Example) | Stability (Std Dev) | Validity |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Standard K-Fold** (Notebook 01) | $6.116 | 1.571 | **FLAWED** (Mixes past and future data) |\n",
    "| **TimeSeriesSplit** (This Notebook) | [Insert TSS Average MAE] | [Insert TSS Std Dev] | **CORRECT** (Respects time order) |\n",
    "\n",
    "### Key Takeaway\n",
    "\n",
    "The **TimeSeriesSplit** result is the **only valid and reliable** way to evaluate a model built for forecasting or any data that relies on a chronological sequence. If you see a low MAE from standard K-Fold on time series data, it is a likely indicator of **data leakage** (cheating)!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
