{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16f4e9fe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "816faa08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 150 samples.\n"
     ]
    }
   ],
   "source": [
    "## ðŸ“š 1. Setup and Data Loading\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score # NEW tool: LeaveOneOut\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# --- Load the Iris Classification Dataset ---\n",
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "n_samples = len(X)\n",
    "print(f\"Dataset loaded: {n_samples} samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066b9e3d",
   "metadata": {},
   "source": [
    "## ðŸ”¬ 2. Introduction to Leave-One-Out CV (LOOCV)\n",
    "\n",
    "**Leave-One-Out Cross-Validation (LOOCV)** is the most extreme form of K-Fold CV.\n",
    "\n",
    "In every other method, $K$ is small (e.g., 5 or 10). In LOOCV:\n",
    "\n",
    "* **The Number of Folds ($K$) equals the Number of Samples ($N$).**\n",
    "\n",
    "### ðŸ§  The LOOCV Process\n",
    "\n",
    "If your dataset has $N=150$ samples:\n",
    "\n",
    "1.  **Experiment 1:** Train the model on **149** samples, and test on **1** sample.\n",
    "2.  **Experiment 2:** Train the model on the other **149** samples, and test on the next single sample.\n",
    "3.  ...\n",
    "4.  **Experiment N (150):** Repeat this process **150 times**.\n",
    "\n",
    "### ðŸ“‰ Pros and Cons\n",
    "\n",
    "| LOOCV Advantage (Pro) | LOOCV Disadvantage (Con) |\n",
    "| :--- | :--- |\n",
    "| **Maximal Data Use:** The training set is almost the size of the original dataset, minimizing bias. | **Extremely slow:** Since you run $N$ experiments, it's computationally prohibitive for large datasets (e.g., 100,000 samples $\\rightarrow$ 100,000 experiments!). |\n",
    "| **Low Variance:** Because training sets are nearly identical, the results are very stable. | High correlation between folds, which can make the score unreliable. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49cabeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeaveOneOut object created. It will perform 150 total experiments.\n",
      "\n",
      "Accuracy scores for the first 10 folds (out of 150):\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "Final LOOCV Score (Average Accuracy): 0.9667\n",
      "Standard Deviation of Accuracy: 0.1795\n"
     ]
    }
   ],
   "source": [
    "## ðŸ“Š 3. LOOCV Implementation\n",
    "\n",
    "# --- ORIGINAL CODE (Causes Warning) ---\n",
    "# model_loo = LogisticRegression(solver='liblinear', random_state=42)\n",
    "\n",
    "# --- CORRECTED CODE (Removes Warning) ---\n",
    "model_loo = LogisticRegression(solver='lbfgs', random_state=42, max_iter=2000)\n",
    "# Note: Increasing max_iter is often needed for lbfgs on classification problems\n",
    "\n",
    "# 3.1. Defining the Folds\n",
    "# The LeaveOneOut object automatically sets the number of splits (K) to the number of samples (N).\n",
    "loo = LeaveOneOut()\n",
    "print(f\"LeaveOneOut object created. It will perform {n_samples} total experiments.\")\n",
    "\n",
    "# Initialize the model\n",
    "# model_loo = LogisticRegression(solver='liblinear', random_state=42)\n",
    "\n",
    "# 3.2. Running the LOOCV\n",
    "# cross_val_score handles the N iterations automatically.\n",
    "cv_scores_loo = cross_val_score(\n",
    "    model_loo, \n",
    "    X, \n",
    "    y, \n",
    "    cv=loo,  # Using the LeaveOneOut object\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "print(\"\\nAccuracy scores for the first 10 folds (out of 150):\")\n",
    "print(cv_scores_loo[:10])\n",
    "\n",
    "print(f\"\\nFinal LOOCV Score (Average Accuracy): {cv_scores_loo.mean():.4f}\")\n",
    "print(f\"Standard Deviation of Accuracy: {cv_scores_loo.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1f0d02",
   "metadata": {},
   "source": [
    "## ðŸŒŸ 4. Conclusion: When to Use LOOCV\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "* The score is the average of 150 individual test scores.\n",
    "* The **Standard Deviation** is usually very low, reflecting the high stability (low variance) of the method, since the training sets for each experiment are almost identical.\n",
    "\n",
    "### ðŸŽ¯ When to Use LOOCV\n",
    "\n",
    "LOOCV is **rarely used** in modern Machine Learning due to its heavy computational cost. It is only considered in specific, niche situations:\n",
    "\n",
    "1.  **Tiny Datasets:** When $N$ is very small (e.g., $N < 50$), and you need to maximize the training data for every single fold.\n",
    "2.  **Model Bias is Critical:** When minimizing the bias (the difference between the training set size and the full dataset size) is the most important factor.\n",
    "\n",
    "For 99% of tasks, **K-Fold ($K=5$ or $K=10$)** is the superior choice, offering a great balance between accuracy and speed.\n",
    "\n",
    "---\n",
    "**Next up:** You've completed the entire theoretical and practical framework for Cross-Validation! Now we move to the next major section: **Hyperparameter Tuning**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
