{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfcbe76a",
   "metadata": {},
   "source": [
    "1. Setup and Data Loading (Code Cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e45b6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data loaded successfully. Shape: (4384, 10)\n",
      "Features engineered. Ready for modeling. Final shape: (51, 14)\n"
     ]
    }
   ],
   "source": [
    "## üìö 1. Setup and Data Loading (with Feature Engineering)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# --- Data Loading ---\n",
    "file_path = '../../datasets/Supplement_Sales_Weekly_Expanded.csv'\n",
    "try:\n",
    "    data = pd.read_csv(file_path) \n",
    "    print(\"Raw data loaded successfully. Shape:\", data.shape)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Please check the path to your prepared dataset.\")\n",
    "    # Exit or raise error if loading fails to prevent subsequent KeyErrors\n",
    "\n",
    "# --- Feature Engineering (Based on your Steps 1 & 2) ---\n",
    "\n",
    "# 1. Data Cleaning and Preparation (Temporal & Grouping)\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data['Year'] = data['Date'].dt.year\n",
    "data['Month'] = data['Date'].dt.month\n",
    "data = data.drop(columns=['Category', 'Revenue', 'Location'], errors='ignore')\n",
    "\n",
    "# Calculate the average monthly price (as per your notes)\n",
    "product_data_grouped = data.groupby(['Product_Name', 'Year', 'Month']).agg(\n",
    "    Price_Avg=('Price', 'mean'), # Calculate the average price\n",
    "    Product_ID=('Product_Name', 'first')\n",
    ").reset_index()\n",
    "\n",
    "# Sort data chronologically for lag/time features\n",
    "product_data_grouped = product_data_grouped.sort_values(by=['Product_Name', 'Year', 'Month']).reset_index(drop=True)\n",
    "\n",
    "# Select a single product for simplicity in this demo\n",
    "PRODUCT_ID = product_data_grouped['Product_Name'].unique()[0]\n",
    "product_data = product_data_grouped[product_data_grouped['Product_Name'] == PRODUCT_ID].copy()\n",
    "\n",
    "\n",
    "# 2. Creating Additional Features (Time & Lag)\n",
    "product_data['Time_Index'] = np.arange(len(product_data)) + 1\n",
    "product_data['Time_Index_Squared'] = product_data['Time_Index'] ** 2\n",
    "\n",
    "# Seasonal Coding\n",
    "product_data['Month_sin'] = np.sin(2 * np.pi * product_data['Month'] / 12)\n",
    "product_data['Month_cos'] = np.cos(2 * np.pi * product_data['Month'] / 12)\n",
    "\n",
    "# Lag Variables (using .shift())\n",
    "product_data['Price_Lag_1'] = product_data['Price_Avg'].shift(1)\n",
    "product_data['Price_Lag_3'] = product_data['Price_Avg'].shift(3)\n",
    "product_data['Price_Lag_12'] = product_data['Price_Avg'].shift(12)\n",
    "\n",
    "# Moving Averages (using .rolling())\n",
    "product_data['Price_MA_6'] = product_data['Price_Avg'].rolling(window=6).mean().shift(1)\n",
    "product_data['Price_MA_12'] = product_data['Price_Avg'].rolling(window=12).mean().shift(1)\n",
    "\n",
    "# Drop initial rows with NaN values created by lags/MA\n",
    "product_data = product_data.dropna().reset_index(drop=True)\n",
    "print(\"Features engineered. Ready for modeling. Final shape:\", product_data.shape)\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "FEATURES = ['Year', 'Month', 'Month_sin', 'Month_cos', 'Time_Index', 'Time_Index_Squared', \n",
    "            'Price_Lag_1', 'Price_Lag_3', 'Price_Lag_12', 'Price_MA_6', 'Price_MA_12']\n",
    "TARGET = 'Price_Avg'\n",
    "\n",
    "X = product_data[FEATURES]\n",
    "y = product_data[TARGET]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dfe410",
   "metadata": {},
   "source": [
    "# üéì 2. The Problem Cross-Validation Solves (Overfitting)\n",
    "\n",
    "We are predicting the average price of a vitamin supplement using a Random Forest model.\n",
    "\n",
    "### üß† The Exam Analogy and Overfitting\n",
    "\n",
    "Imagine your **Model is a student** and your **Data is the exam material**.\n",
    "\n",
    "> If you test your model using the **same data** it used to learn (study), the model will get a great score. This is called **overfitting**‚Äîthe model has simply **memorized the answers** instead of learning the general concepts.\n",
    ">\n",
    "> That great score is a **fake measure** of how well the model will perform on **new, unseen data** in the real world.\n",
    "\n",
    "### ‚ö†Ô∏è The Problem with a Single Split\n",
    "\n",
    "In our original project, we used a single **80/20 train-test split**, respecting the chronological order (training on older data, testing on newer data).\n",
    "\n",
    "While respecting time is good, relying on **just one single split** has a major flaw:\n",
    "\n",
    "1.  **Luck/Unluck:** If the 20% test period happens to contain unusual, scattered prices (noise), our final score will look worse than it really is.\n",
    "2.  **No Confidence Interval:** We get one score (e.g., MAE = 0.50). We don't know if that score is stable or just a lucky/unlucky result from that specific time window.\n",
    "\n",
    "**Cross-Validation fixes this by performing many fair, independent tests.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00eb92c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 40 samples. Test size: 11 samples.\n",
      "\n",
      "Single Train-Test MAE (Mean Absolute Error): $4.998\n"
     ]
    }
   ],
   "source": [
    "## üìâ 3. The Unreliable Single Train-Test Split\n",
    "\n",
    "# 3.1. Single split (Chronological)\n",
    "# Since this is time-series data, we split chronologically (80% for train, 20% for test)\n",
    "split_point = int(len(X) * 0.80)\n",
    "X_train, X_test = X[:split_point], X[split_point:]\n",
    "y_train, y_test = y[:split_point], y[split_point:]\n",
    "\n",
    "print(f\"Train size: {len(X_train)} samples. Test size: {len(X_test)} samples.\")\n",
    "\n",
    "\n",
    "# 3.2. Train and Evaluate\n",
    "model_single = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model_single.fit(X_train, y_train)\n",
    "\n",
    "y_pred_single = model_single.predict(X_test)\n",
    "\n",
    "mae_single = mean_absolute_error(y_test, y_pred_single)\n",
    "print(f\"\\nSingle Train-Test MAE (Mean Absolute Error): ${mae_single:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992efbfb",
   "metadata": {},
   "source": [
    "# 3.3. Interpretation (Markdown Cell)\n",
    "### Interpretation of Single Split\n",
    "\n",
    "We achieved a Mean Absolute Error (MAE) of **[Insert MAE from above]**.\n",
    "\n",
    "**Question:** Is this a robust score? What if we had tested on a different 20% period? We have no way to know.\n",
    "\n",
    "This is why we need Cross-Validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad3d068",
   "metadata": {},
   "source": [
    "## üîÅ 4. Introducing K-Fold Cross-Validation\n",
    "\n",
    "Instead of one single test, K-Fold CV gives our model **multiple, independent tests**.\n",
    "\n",
    "We split the entire dataset into **K** equal pieces (folds). We then run **K** separate experiments, rotating which piece is used for testing:\n",
    "\n",
    "| Experiment | Training Data | Testing Data (Validation) |\n",
    "| :--- | :--- | :--- |\n",
    "| **Fold 1** | Folds 2, 3, 4, 5 | **Fold 1** |\n",
    "| **Fold 2** | Folds 1, 3, 4, 5 | **Fold 2** |\n",
    "| ... | ... | ... |\n",
    "\n",
    "**Note on Time Series:** For true time-series data, standard K-Fold is usually not correct because it mixes past and future data. However, for a basic introduction, we will use it here to demonstrate the *averaging* concept. (We will address the proper time-series CV in a later notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f8be921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual MAE scores for each fold (test):\n",
      "[7.61504818 4.311373   8.2899025  5.60471    4.758919  ]\n",
      "\n",
      "Final CV Score (Average MAE): $6.116\n",
      "Standard Deviation of MAE: 1.571\n"
     ]
    }
   ],
   "source": [
    "## üìä 5. Implementing K-Fold CV (5 Folds)\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# Use K=5 for this introduction\n",
    "kf = KFold(n_splits=5, shuffle=False) # shuffle=False maintains the time order within folds, though the folds themselves are not strictly chronological splits.\n",
    "\n",
    "# Re-initialize the model\n",
    "model_cv = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Use cross_val_score: Note that 'neg_mean_absolute_error' is used because scikit-learn\n",
    "# treats scoring metrics as something to be maximized (higher is better).\n",
    "# The negative sign converts the error into a \"score.\"\n",
    "cv_scores = cross_val_score(\n",
    "    model_cv, \n",
    "    X, \n",
    "    y, \n",
    "    cv=kf, \n",
    "    scoring='neg_mean_absolute_error'\n",
    ")\n",
    "\n",
    "# Convert negative scores back to positive MAE errors\n",
    "cv_maes = -cv_scores \n",
    "\n",
    "print(\"Individual MAE scores for each fold (test):\")\n",
    "print(cv_maes)\n",
    "\n",
    "print(f\"\\nFinal CV Score (Average MAE): ${cv_maes.mean():.3f}\")\n",
    "print(f\"Standard Deviation of MAE: {cv_maes.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c64cbb7",
   "metadata": {},
   "source": [
    "## **üåü 6\\. Conclusion: A Reliable Score**\n",
    "\n",
    "Now we can directly compare the result from the single, potentially unreliable test against the more robust Cross-Validation (CV) average.\n",
    "\n",
    "| Metric | Single Split (80/20) Result | K-Fold CV (Average) Result |\n",
    "| :---- | :---- | :---- |\n",
    "| **MAE** | **$4.998** | **$6.116** |\n",
    "| **Robustness** | Low (Based on one single test period) | High (Based on 5 different test periods) |\n",
    "\n",
    "### **üß† What These Results Tell Us**\n",
    "\n",
    "1. **The Single Split was Optimistic (and Likely Unreliable):**  \n",
    "   * Your initial single test score of **$4.998** was quite low. This suggests that the final 20% of the data used for the test might have been an **easier, less noisy period** for the model to predict.  \n",
    "   * If you had relied only on that $4.998 score, you would have **overestimated** your model's real-world accuracy.  \n",
    "2. **The CV Score is the Honest Grade:**  \n",
    "   * The **Average MAE of $6.116** is the model's true, general performance. This score is much more trustworthy because it ensures that **every part of your data** has been used fairly for testing.  \n",
    "3. **The Model's Performance Varies:**  \n",
    "   * The **Individual MAE Scores** ranged from **$4.311** to **$8.290**.  \n",
    "   * The **Standard Deviation of 1.571** shows that the model's prediction accuracy changes significantly depending on the time period it's tested on. A high standard deviation means the model is **not perfectly stable**.  \n",
    "   * This is a strong sign that the model may be struggling with high **variance** (a form of instability), which is exactly what CV is designed to expose\\!\n",
    "\n",
    "**In summary, Cross-Validation gave your model an honest, overall grade of $6.116, revealing that its performance is less stable than the single initial test suggested.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
